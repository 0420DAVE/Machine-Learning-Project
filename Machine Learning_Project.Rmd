---
title: "Machine Learning"
author: "Li Ying"
date: "24 May 2015"
output: html_document
---

Prepare data
```{r}
library(data.table)

url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
D <- fread(url)
url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
DTest <- fread(url)
```

```{r}
na.omit(DTest)
isAnyMissing <- sapply(DTest, function (x) any(is.na(x) | x == ""))
isPredictor <- !isAnyMissing & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(isAnyMissing))
predCandidates <- names(isAnyMissing)[isPredictor]
predCandidates
```

Subset the primary dataset to include only the predictor candidates and the outcome variable.
```{r}
varToInclude <- c("classe", predCandidates)
D <- D[, varToInclude, with=FALSE]

# change class
D$class<-as.factor(D$class)
D[, .N, classe]

```

split data into 60% training and 40% prob
```{r}
library(caret)
seed <- as.numeric(as.Date("2014-10-26"))
set.seed(seed)
inTrain <- createDataPartition(D$classe, p=0.6)
DTrain <- D[inTrain[[1]]]
DProbe <- D[-inTrain[[1]]]
```

Preprocess the prediction variables by centering and scaling.
```{r}
X <- DTrain[, predCandidates, with=FALSE]
preProc <- preProcess(X)
preProc
```

```{r}
XCS <- predict(preProc, X)
DTrainCS <- data.table(data.frame(classe = DTrain[, classe], XCS))
```

Apply the centering and scaling to the probing dataset.

```{r}
X <- DProbe[, predCandidates, with=FALSE]
XCS <- predict(preProc, X)
DProbeCS <- data.table(data.frame(classe = DProbe[, classe], XCS))
```

Check for near zero variance.
```{r}
nzv <- nearZeroVar(DTrainCS, saveMetrics=TRUE)
if (any(nzv$nzv)) nzv else message("No variables with near zero variance")
```

Exploratory data analysis
```{r}
histGroup <- function (data, regex) {
  col <- grep(regex, names(data))
  col <- c(col, which(names(data) == "classe"))
  library(reshape2)
  n <- nrow(data)
  DMelted <- melt(data[, col, with=FALSE][, rownum := seq(1, n)], id.vars=c("rownum", "classe"))
  library(ggplot2)
  ggplot(DMelted, aes(x=classe, y=value)) +
    geom_violin(aes(color=classe, fill=classe), alpha=1/2) +
#     geom_jitter(aes(color=classe, fill=classe), alpha=1/10) +
#     geom_smooth(aes(group=1), method="gam", color="black", alpha=1/2, size=2) +
    facet_wrap(~ variable, scale="free_y") +
    scale_color_brewer(palette="Spectral") +
    scale_fill_brewer(palette="Spectral") +
    labs(x="", y="") +
    theme(legend.position="none")
}
histGroup(DTrainCS, "belt")
histGroup(DTrainCS, "[^(fore)]arm")
```


## Train a prediction model
```{r}
library(parallel)
library(doParallel)
library(caret)
```

```{r}
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

#set controlled parameters
ctrl <- trainControl(classProbs=TRUE,
                     savePredictions=TRUE,
                     allowParallel=TRUE)

#Fit model over the tuning parameters.
method <- "rf"
system.time(trainingModel <- train(classe ~ ., data=DTrainCS, method=method))

#Stop the clusters.
stopCluster(cl)
```
## Evaluate model on training dataset
```{r}
trainingModel

hat <- predict(trainingModel, DTrainCS)
confusionMatrix(hat, DTrain[, classe])
```

##Evaluate the model on the probing dataset
```{r}
hat <- predict(trainingModel, DProbeCS)
confusionMatrix(hat, DProbeCS[, classe])
```

Display final model
```{r}
varImp(trainingModel)
trainingModel$finalModel
#save training model
save(trainingModel, file="trainingModel.RData")
```

##Predict on the test data
```{r}
load(file="trainingModel.RData", verbose=TRUE)
```
get prediction and evaluate
```{r}
DTestCS <- predict(preProc, DTest[, predCandidates, with=FALSE])
hat <- predict(trainingModel, DTestCS)
DTest <- cbind(hat , DTest)
subset(DTest, select=names(DTest)[grep("belt|[^(fore)]arm|dumbbell|forearm", names(DTest), invert=TRUE)])
```


## SUBMISSION
```{r}
pml_write_files = function(x){
  n = length(x)
  path <- "predictionAssignment_files/answers"
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=file.path(path, filename),quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(hat)
```















